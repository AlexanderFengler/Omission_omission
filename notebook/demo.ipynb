{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102b6688-0250-4ae1-a337-6e38f97632b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4386390a-e6f0-4648-af4c-cf289ad26af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb not available\n",
      "wandb not available\n"
     ]
    }
   ],
   "source": [
    "import ssms\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import lanfactory\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pymc.sampling import jax as pmj\n",
    "import arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584f7ae-e653-4681-b5eb-7ecccbe07406",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccccfbb-9c1b-4ce6-b522-4313c1011459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'angle',\n",
       " 'params': ['v', 'a', 'z', 't', 'theta'],\n",
       " 'param_bounds': [[-3.0, 0.3, 0.1, 0.001, -0.1], [3.0, 3.0, 0.9, 2.0, 1.3]],\n",
       " 'boundary': <function ssms.basic_simulators.boundary_functions.angle(t=1, theta=1)>,\n",
       " 'n_params': 5,\n",
       " 'default_params': [0.0, 1.0, 0.5, 0.001, 0.0],\n",
       " 'hddm_include': ['z', 'theta'],\n",
       " 'nchoices': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssms.config.model_config['angle']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674daa7-e01e-4df8-be5c-87ddd5077434",
   "metadata": {},
   "source": [
    "# Set up the functions for jax and pytensor wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5853a6a4-4525-414f-85a0-9837a491da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import PathLike\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "import pytensor \n",
    "pytensor.config.floatX = \"float32\"\n",
    "import pytensor.tensor as pt\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.special import expit\n",
    "import numpy as np\n",
    "from pytensor.graph import Apply, Op\n",
    "from pytensor.link.jax.dispatch import jax_funcify\n",
    "from jax import jit, vjp, vmap\n",
    "from jax import grad, jit\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "LogLikeFunc = Callable[..., ArrayLike]\n",
    "LogLikeGrad = Callable[..., ArrayLike]\n",
    "\n",
    "import pymc as pm\n",
    "from pytensor.tensor.random.op import RandomVariable\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from jax.config import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "class NetworkLike:\n",
    "    @classmethod\n",
    "    def make_logp_jax_funcs(\n",
    "        cls,\n",
    "        params_is_reg: list[bool],\n",
    "        list_params: list,\n",
    "        model = None,\n",
    "        n_params: int | None = None,\n",
    "        bounds = None,\n",
    "        kind: str = 'lan',\n",
    "    ) -> Tuple[LogLikeFunc, LogLikeGrad, LogLikeFunc,]:\n",
    "        \"\"\"Makes a jax log likelihood function from flax network forward pass.\n",
    "        Args:\n",
    "            model: A path or url to the ONNX model, or an ONNX Model object\n",
    "            already loaded.\n",
    "            compile: Whether to use jit in jax to compile the model.\n",
    "        Returns: A triple of jax or Python functions. The first calculates the\n",
    "            forward pass, the second calculates the gradient, and the third is\n",
    "            the forward-pass that's not jitted.\n",
    "        \"\"\"\n",
    "        if kind == 'lan':\n",
    "            def logp_lan(data: np.ndarray, *dist_params) -> ArrayLike:\n",
    "                \"\"\"\n",
    "                Computes the sum of the log-likelihoods given data and arbitrary\n",
    "                numbers of parameters assuming the trial by trial likelihoods\n",
    "                are derived from a LAN.\n",
    "                Args:\n",
    "                    data: response time with sign indicating direction.\n",
    "                    dist_params: a list of parameters used in the likelihood computation.\n",
    "                Returns:\n",
    "                    The sum of log-likelihoods.\n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "                transformed_params = []\n",
    "                for i in range(len(dist_params)):\n",
    "                    if list_params[i] in bounds.keys():\n",
    "                        transformed_params.append(expit(dist_params[i]) * (bounds[list_params[i]][1] - bounds[list_params[i]][0]) + bounds[list_params[i]][0])\n",
    "                    else:\n",
    "                        transformed_params.append(dist_params[i])\n",
    "                input_matrix = jnp.concatenate((jnp.array(transformed_params[:-1]), data))\n",
    "\n",
    "                ll = jnp.multiply(jnp.exp(model(input_matrix)),1-transformed_params[-1]) + transformed_params[-1] * 1/2.5\n",
    "\n",
    "                # Network forward and sum\n",
    "                return jnp.sum(\n",
    "                    jnp.squeeze(jnp.log(ll))\n",
    "                )\n",
    "            # The vectorization of the logp function\n",
    "            vmap_logp_lan = vmap(\n",
    "                logp_lan,\n",
    "                in_axes=[0] + [0 if is_regression else None for is_regression in params_is_reg],\n",
    "            )\n",
    "            # logp_grad_lan = grad(logp_lan, argnums=range(1, 1 + n_params))\n",
    "            # return jit(logp_lan), jit(logp_grad_lan), logp_lan\n",
    "            \n",
    "            def vjp_vmap_logp_lan(\n",
    "                data: np.ndarray, *dist_params: list[float | ArrayLike], gz: ArrayLike\n",
    "            ) -> list[ArrayLike]:\n",
    "                \"\"\"Compute the VJP of the log-likelihood function.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                data\n",
    "                    A two-column numpy array with response time and response.\n",
    "                dist_params\n",
    "                    A list of parameters used in the likelihood computation.\n",
    "                gz\n",
    "                    The value of vmap_logp at which the VJP is evaluated, typically is just\n",
    "                    vmap_logp(data, *dist_params)\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                list[ArrayLike]\n",
    "                    The VJP of the log-likelihood function computed at gz.\n",
    "                \"\"\"\n",
    "                _, vjp_fn = vjp(vmap_logp_lan, data, *dist_params)\n",
    "                return vjp_fn(gz)[1:]\n",
    "\n",
    "            return jit(vmap_logp_lan), jit(vjp_vmap_logp_lan), vmap_logp_lan\n",
    "\n",
    "        elif kind == 'cpn':\n",
    "            def logp_cpn(data: np.ndarray, *dist_params) -> ArrayLike:\n",
    "                \"\"\"\n",
    "                Computes the sum of the log-likelihoods given data and arbitrary\n",
    "                numbers of parameters assuming the trial-by-trial likelihood derive for a CPN.\n",
    "                Args:\n",
    "                    data: response time with sign indicating direction.\n",
    "                    dist_params: a list of parameters used in the likelihood computation.\n",
    "                Returns:\n",
    "                    The sum of log-likelihoods.\n",
    "                \"\"\"\n",
    "\n",
    "                # Makes a matrix to feed to the LAN model\n",
    "                # n_nogo_go_condition = jnp.sum(data > 0)\n",
    "                # n_nogo_nogo_condition = jnp.sum(data < 0)\n",
    "                # n_omission = jnp.sum(data>0)\n",
    "                # n_total = jnp.sum(data>=0)\n",
    "                transformed_params = []\n",
    "\n",
    "                for i in range(len(dist_params)):\n",
    "                    if list_params[i] in bounds.keys():\n",
    "                        transformed_params.append(expit(dist_params[i]) * (bounds[list_params[i]][1] - bounds[list_params[i]][0]) + bounds[list_params[i]][0])\n",
    "                    else:\n",
    "                        transformed_params.append(dist_params[i])\n",
    "                        \n",
    "                params_matrix  = jnp.array(transformed_params)\n",
    "\n",
    "                # AF-TODO Bugfix here !\n",
    "                # dist_params_nogo = jnp.stack(dist_params).reshape(1, -1)\n",
    "                # dist_params_nogo = dist_params_nogo.at[0].set((-1) * dist_params_nogo[0])\n",
    "\n",
    "                net_out = jnp.squeeze(model(params_matrix))\n",
    "\n",
    "                # Include lapse distribution (uniform) into omission likelihood\n",
    "                # dist_params[-1]: outlier\n",
    "                # dist_params[-2]: deadline (in second)\n",
    "\n",
    "                out = jnp.sum(jnp.multiply(jnp.log(1 - jnp.exp(net_out) + 1e-64),data))\n",
    "\n",
    "                return out\n",
    "            vmap_logp_cpn = vmap(\n",
    "                logp_cpn,\n",
    "                in_axes=[0] + [0 if is_regression else None for is_regression in params_is_reg],\n",
    "            )\n",
    "            def vjp_vmap_logp_cpn(\n",
    "                data: np.ndarray, *dist_params: list[float | ArrayLike], gz: ArrayLike\n",
    "            ) -> list[ArrayLike]:\n",
    "                \"\"\"Compute the VJP of the log-likelihood function.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                data\n",
    "                    A two-column numpy array with response time and response.\n",
    "                dist_params\n",
    "                    A list of parameters used in the likelihood computation.\n",
    "                gz\n",
    "                    The value of vmap_logp at which the VJP is evaluated, typically is just\n",
    "                    vmap_logp(data, *dist_params)\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                list[ArrayLike]\n",
    "                    The VJP of the log-likelihood function computed at gz.\n",
    "                \"\"\"\n",
    "                _, vjp_fn = vjp(vmap_logp_cpn, data, *dist_params)\n",
    "                return vjp_fn(gz)[1:]\n",
    "\n",
    "            return jit(vmap_logp_cpn), jit(vjp_vmap_logp_cpn), vmap_logp_cpn\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def make_jax_logp_ops(\n",
    "        logp: LogLikeFunc,\n",
    "        logp_vjp: LogLikeGrad,\n",
    "        logp_nojit: LogLikeFunc,\n",
    "    ) -> Op:\n",
    "        \"\"\"Wrap the JAX functions and its gradient in pytensor Ops.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        logp\n",
    "            A JAX function that represents the feed-forward operation of the LAN\n",
    "            network.\n",
    "        logp_vjp\n",
    "            The Jax function that calculates the VJP of the logp function.\n",
    "        logp_nojit\n",
    "            The non-jit version of logp.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Op\n",
    "            An pytensor op that wraps the feed-forward operation and can be used with\n",
    "            pytensor.grad.\n",
    "        \"\"\"\n",
    "\n",
    "        class LANLogpOp(Op):  # pylint: disable=W0223\n",
    "            \"\"\"Wraps a JAX function in an pytensor Op.\"\"\"\n",
    "\n",
    "            def make_node(self, data, *dist_params):\n",
    "                \"\"\"Take the inputs to the Op and puts them in a list.\n",
    "\n",
    "                Also specifies the output types in a list, then feed them to the Apply node.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                data\n",
    "                    A two-column numpy array with response time and response.\n",
    "                dist_params\n",
    "                    A list of parameters used in the likelihood computation. The parameters\n",
    "                    can be both scalars and arrays.\n",
    "                \"\"\"\n",
    "                inputs = [\n",
    "                    pt.as_tensor_variable(data),\n",
    "                ] + [pt.as_tensor_variable(dist_param) for dist_param in dist_params]\n",
    "\n",
    "                outputs = [pt.vector()]\n",
    "\n",
    "                return Apply(self, inputs, outputs)\n",
    "\n",
    "            def perform(self, node, inputs, output_storage):\n",
    "                \"\"\"Perform the Apply node.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                inputs\n",
    "                    This is a list of data from which the values stored in\n",
    "                    output_storage are to be computed using non-symbolic language.\n",
    "                output_storage\n",
    "                    This is a list of storage cells where the output\n",
    "                    is to be stored. A storage cell is a one-element list. It is\n",
    "                    forbidden to change the length of the list(s) contained in\n",
    "                    output_storage. There is one storage cell for each output of\n",
    "                    the Op.\n",
    "                \"\"\"\n",
    "                result = logp(*inputs)\n",
    "                output_storage[0][0] = np.asarray(result, dtype=node.outputs[0].dtype)\n",
    "\n",
    "            def grad(self, inputs, output_gradients):\n",
    "                \"\"\"Perform the pytensor.grad() operation.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                inputs\n",
    "                    The same as the inputs produced in `make_node`.\n",
    "                output_gradients\n",
    "                    Holds the results of the perform `perform` method.\n",
    "\n",
    "                Notes\n",
    "                -----\n",
    "                    It should output the VJP of the Op. In other words, if this `Op`\n",
    "                    outputs `y`, and the gradient at `y` is grad(x), the required output\n",
    "                    is y*grad(x).\n",
    "                \"\"\"\n",
    "                results = lan_logp_vjp_op(inputs[0], *inputs[1:], gz=output_gradients[0])\n",
    "                output = [\n",
    "                    pytensor.gradient.grad_not_implemented(self, 0, inputs[0]),\n",
    "                ] + results\n",
    "\n",
    "                return output\n",
    "\n",
    "        class LANLogpVJPOp(Op):  # pylint: disable=W0223\n",
    "            \"\"\"Wraps the VJP operation of a jax function in an pytensor op.\"\"\"\n",
    "\n",
    "            def make_node(self, data, *dist_params, gz):\n",
    "                \"\"\"Take the inputs to the Op and puts them in a list.\n",
    "\n",
    "                Also specifies the output types in a list, then feed them to the Apply node.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                data:\n",
    "                    A two-column numpy array with response time and response.\n",
    "                dist_params:\n",
    "                    A list of parameters used in the likelihood computation.\n",
    "                \"\"\"\n",
    "                inputs = (\n",
    "                    [\n",
    "                        pt.as_tensor_variable(data),\n",
    "                    ]\n",
    "                    + [pt.as_tensor_variable(dist_param) for dist_param in dist_params]\n",
    "                    + [pt.as_tensor_variable(gz)]\n",
    "                )\n",
    "                outputs = [inp.type() for inp in inputs[1:-1]]\n",
    "\n",
    "                return Apply(self, inputs, outputs)\n",
    "\n",
    "            def perform(self, node, inputs, outputs):\n",
    "                \"\"\"Perform the Apply node.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                inputs\n",
    "                    This is a list of data from which the values stored in\n",
    "                    `output_storage` are to be computed using non-symbolic language.\n",
    "                output_storage\n",
    "                    This is a list of storage cells where the output\n",
    "                    is to be stored. A storage cell is a one-element list. It is\n",
    "                    forbidden to change the length of the list(s) contained in\n",
    "                    output_storage. There is one storage cell for each output of\n",
    "                    the Op.\n",
    "                \"\"\"\n",
    "                results = logp_vjp(inputs[0], *inputs[1:-1], gz=inputs[-1])\n",
    "\n",
    "                for i, result in enumerate(results):\n",
    "                    outputs[i][0] = np.asarray(result, dtype=node.outputs[i].dtype)\n",
    "\n",
    "        lan_logp_op = LANLogpOp()\n",
    "        lan_logp_vjp_op = LANLogpVJPOp()\n",
    "\n",
    "        # Unwraps the JAX function for sampling with JAX backend.\n",
    "        @jax_funcify.register(LANLogpOp)\n",
    "        def logp_op_dispatch(op, **kwargs):  # pylint: disable=W0612,W0613\n",
    "            return logp_nojit\n",
    "\n",
    "        return lan_logp_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b54085-e99f-431e-920c-e0ece0a5bdbb",
   "metadata": {},
   "source": [
    "# Load LAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dce9a9a-d6eb-459a-8225-f2f3bd451bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing through identity\n"
     ]
    }
   ],
   "source": [
    "# Loaded Net\n",
    "model_config = ssms.config.model_config['angle']\n",
    "\n",
    "jax_infer_lan = lanfactory.trainers.MLPJaxFactory(\n",
    "    network_config=\"../network/angle/lan/96f2b24a933211ee99b9a0423f3e9a40_lan_angle__network_config.pickle\",\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "forward_pass_lan, forward_pass_jitted_lan = jax_infer_lan.make_forward_partial(\n",
    "    seed=42,\n",
    "    input_dim=model_config[\"n_params\"] + 2,\n",
    "    state=\"../network/angle/lan/96f2b24a933211ee99b9a0423f3e9a40_lan_angle__train_state.jax\",\n",
    "    add_jitted=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f2568-ed90-44be-9b2e-d381fb950294",
   "metadata": {},
   "source": [
    "# Load OPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aee1dfa-afb4-4996-9b20-042f368fbb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing through transform\n"
     ]
    }
   ],
   "source": [
    "# Loaded Net\n",
    "jax_infer_cpn = lanfactory.trainers.MLPJaxFactory(\n",
    "    network_config=\"../network/angle/cpn/338ff01ca91911ee91a3a0423f3e9b42_cpn_angle__network_config.pickle\",\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "forward_pass_cpn, forward_pass_jitted_cpn = jax_infer_cpn.make_forward_partial(\n",
    "    seed=42,\n",
    "    input_dim=model_config[\"n_params\"] + 1,\n",
    "    state=\"../network/angle/cpn/338ff01ca91911ee91a3a0423f3e9b42_cpn_angle__train_state.jax\",\n",
    "    add_jitted=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31fdba-1ec9-48de-b45d-a5c5a0720836",
   "metadata": {},
   "source": [
    "# This is the part I loaded the dataset. You can ignore this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1df9f5-a1af-412b-b02e-139327a77723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_srm = pd.read_csv('/users/xleng/TSS_OCD/data/2022-04-11_4.0/fa_subset.csv')\n",
    "\n",
    "df_srm['subj_idx'] = df_srm['PROLIFIC_PID']\n",
    "df_srm['subject'] = df_srm['subj_idx'].factorize()[0]\n",
    "\n",
    "df_idx = df_srm[['subj_idx','subject']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f4f24d-98df-40b2-949a-321fd414d3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MR1_NO</th>\n",
       "      <th>MR2_NO</th>\n",
       "      <th>MR1_O</th>\n",
       "      <th>MR2_O</th>\n",
       "      <th>PROLIFIC_PID</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Pro</th>\n",
       "      <th>Pre</th>\n",
       "      <th>subj_idx</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.436324</td>\n",
       "      <td>1.673657</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>60fd2ca6bf8d050ebf440221</td>\n",
       "      <td>-1.328178</td>\n",
       "      <td>-0.683701</td>\n",
       "      <td>0.937111</td>\n",
       "      <td>60fd2ca6bf8d050ebf440221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112875</td>\n",
       "      <td>-0.357938</td>\n",
       "      <td>0.287001</td>\n",
       "      <td>-0.477968</td>\n",
       "      <td>5c3d376ec2d0b700017c7c50</td>\n",
       "      <td>-0.674127</td>\n",
       "      <td>-1.109457</td>\n",
       "      <td>-0.207784</td>\n",
       "      <td>5c3d376ec2d0b700017c7c50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.007355</td>\n",
       "      <td>1.324592</td>\n",
       "      <td>1.861469</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>6103159a48c853995ad5039a</td>\n",
       "      <td>-0.968450</td>\n",
       "      <td>-0.470824</td>\n",
       "      <td>0.708132</td>\n",
       "      <td>6103159a48c853995ad5039a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.518625</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>3.012727</td>\n",
       "      <td>-0.982447</td>\n",
       "      <td>5b92f80b2f777d000175da5c</td>\n",
       "      <td>0.699379</td>\n",
       "      <td>-1.109457</td>\n",
       "      <td>-1.810637</td>\n",
       "      <td>5b92f80b2f777d000175da5c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.384611</td>\n",
       "      <td>0.733107</td>\n",
       "      <td>-0.772784</td>\n",
       "      <td>1.042902</td>\n",
       "      <td>60712d937752fb8780e89951</td>\n",
       "      <td>0.928297</td>\n",
       "      <td>-0.045068</td>\n",
       "      <td>-1.123700</td>\n",
       "      <td>60712d937752fb8780e89951</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-1.019517</td>\n",
       "      <td>-0.543781</td>\n",
       "      <td>-0.999801</td>\n",
       "      <td>-0.229666</td>\n",
       "      <td>5d19281012e152001920227f</td>\n",
       "      <td>-0.968450</td>\n",
       "      <td>-0.470824</td>\n",
       "      <td>0.708132</td>\n",
       "      <td>5d19281012e152001920227f</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.699188</td>\n",
       "      <td>2.345177</td>\n",
       "      <td>-0.145930</td>\n",
       "      <td>2.531872</td>\n",
       "      <td>5e79b84d4633bc575ddb3812</td>\n",
       "      <td>0.699379</td>\n",
       "      <td>0.167810</td>\n",
       "      <td>-0.665742</td>\n",
       "      <td>5e79b84d4633bc575ddb3812</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.952481</td>\n",
       "      <td>-0.817260</td>\n",
       "      <td>-0.803674</td>\n",
       "      <td>-0.586848</td>\n",
       "      <td>5ff5f7ad932d56101bf7c90d</td>\n",
       "      <td>-1.099260</td>\n",
       "      <td>0.380687</td>\n",
       "      <td>1.624048</td>\n",
       "      <td>5ff5f7ad932d56101bf7c90d</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>-0.570416</td>\n",
       "      <td>-0.832249</td>\n",
       "      <td>-0.336753</td>\n",
       "      <td>-0.764156</td>\n",
       "      <td>5d9d2e421af9ed0011c31894</td>\n",
       "      <td>-0.052779</td>\n",
       "      <td>1.232198</td>\n",
       "      <td>1.166090</td>\n",
       "      <td>5d9d2e421af9ed0011c31894</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>-0.054423</td>\n",
       "      <td>0.730188</td>\n",
       "      <td>-0.373492</td>\n",
       "      <td>0.901750</td>\n",
       "      <td>5daa3d1726488800157a6ffc</td>\n",
       "      <td>-1.589798</td>\n",
       "      <td>-0.257946</td>\n",
       "      <td>1.624048</td>\n",
       "      <td>5daa3d1726488800157a6ffc</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MR1_NO    MR2_NO     MR1_O     MR2_O              PROLIFIC_PID  \\\n",
       "0    2.436324  1.673657  2.231432  0.999315  60fd2ca6bf8d050ebf440221   \n",
       "1    0.112875 -0.357938  0.287001 -0.477968  5c3d376ec2d0b700017c7c50   \n",
       "2    2.007355  1.324592  1.861469  0.757895  6103159a48c853995ad5039a   \n",
       "3    2.518625  0.056017  3.012727 -0.982447  5b92f80b2f777d000175da5c   \n",
       "4   -0.384611  0.733107 -0.772784  1.042902  60712d937752fb8780e89951   \n",
       "..        ...       ...       ...       ...                       ...   \n",
       "311 -1.019517 -0.543781 -0.999801 -0.229666  5d19281012e152001920227f   \n",
       "312  0.699188  2.345177 -0.145930  2.531872  5e79b84d4633bc575ddb3812   \n",
       "313 -0.952481 -0.817260 -0.803674 -0.586848  5ff5f7ad932d56101bf7c90d   \n",
       "314 -0.570416 -0.832249 -0.336753 -0.764156  5d9d2e421af9ed0011c31894   \n",
       "315 -0.054423  0.730188 -0.373492  0.901750  5daa3d1726488800157a6ffc   \n",
       "\n",
       "         Bias       Pro       Pre                  subj_idx  subject  \n",
       "0   -1.328178 -0.683701  0.937111  60fd2ca6bf8d050ebf440221        0  \n",
       "1   -0.674127 -1.109457 -0.207784  5c3d376ec2d0b700017c7c50        1  \n",
       "2   -0.968450 -0.470824  0.708132  6103159a48c853995ad5039a        2  \n",
       "3    0.699379 -1.109457 -1.810637  5b92f80b2f777d000175da5c        3  \n",
       "4    0.928297 -0.045068 -1.123700  60712d937752fb8780e89951        4  \n",
       "..        ...       ...       ...                       ...      ...  \n",
       "311 -0.968450 -0.470824  0.708132  5d19281012e152001920227f      311  \n",
       "312  0.699379  0.167810 -0.665742  5e79b84d4633bc575ddb3812      312  \n",
       "313 -1.099260  0.380687  1.624048  5ff5f7ad932d56101bf7c90d      313  \n",
       "314 -0.052779  1.232198  1.166090  5d9d2e421af9ed0011c31894      314  \n",
       "315 -1.589798 -0.257946  1.624048  5daa3d1726488800157a6ffc      315  \n",
       "\n",
       "[316 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_srm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab93151-7e9f-40b7-9f29-6263461953c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/users/xleng/TSS_OCD/data/2022-04-11_4.0/hddm_all.csv')\n",
    "\n",
    "df = df.merge(df_srm[['subj_idx','subject']])\n",
    "\n",
    "df['catRewLevel'] = df['catRewLevel'].factorize()[0]\n",
    "\n",
    "df['catPunLevel'] = df['catPunLevel'].factorize()[0]\n",
    "\n",
    "df['catCong'] = df['catCong'].factorize()[0]\n",
    "\n",
    "df['response'] = df['response'] * 2 - 1\n",
    "\n",
    "df['catRewLevel'] = df['catRewLevel'] * 2 - 1\n",
    "\n",
    "df['catPunLevel'] = df['catPunLevel'] * 2 - 1\n",
    "\n",
    "df['rewpunLevel'] = df['catRewLevel'] * df['catPunLevel']\n",
    "\n",
    "df['catCong'] = df['catCong'] * 2 - 1\n",
    "\n",
    "df_commission = df.loc[df['oe'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d2e6ab-66b7-415b-8124-7e59d74a2d31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>catRewLevel</th>\n",
       "      <th>catPunLevel</th>\n",
       "      <th>oe</th>\n",
       "      <th>subj_idx</th>\n",
       "      <th>response</th>\n",
       "      <th>catCong</th>\n",
       "      <th>subject</th>\n",
       "      <th>rewpunLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.591</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>60fd2ca6bf8d050ebf440221</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>60fd2ca6bf8d050ebf440221</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.648</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>60fd2ca6bf8d050ebf440221</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.330</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>60fd2ca6bf8d050ebf440221</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.307</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>60fd2ca6bf8d050ebf440221</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172708</th>\n",
       "      <td>0.742</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5daa3d1726488800157a6ffc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172709</th>\n",
       "      <td>0.638</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5daa3d1726488800157a6ffc</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>315</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172710</th>\n",
       "      <td>0.918</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5daa3d1726488800157a6ffc</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>315</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172711</th>\n",
       "      <td>0.734</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5daa3d1726488800157a6ffc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172712</th>\n",
       "      <td>0.830</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5daa3d1726488800157a6ffc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165348 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rt  catRewLevel  catPunLevel     oe                  subj_idx  \\\n",
       "0       0.591           -1           -1  False  60fd2ca6bf8d050ebf440221   \n",
       "1       0.538           -1           -1  False  60fd2ca6bf8d050ebf440221   \n",
       "2       0.648           -1           -1  False  60fd2ca6bf8d050ebf440221   \n",
       "3       0.330           -1           -1  False  60fd2ca6bf8d050ebf440221   \n",
       "4       0.307           -1           -1  False  60fd2ca6bf8d050ebf440221   \n",
       "...       ...          ...          ...    ...                       ...   \n",
       "172708  0.742           -1            1  False  5daa3d1726488800157a6ffc   \n",
       "172709  0.638           -1            1  False  5daa3d1726488800157a6ffc   \n",
       "172710  0.918           -1            1  False  5daa3d1726488800157a6ffc   \n",
       "172711  0.734           -1            1  False  5daa3d1726488800157a6ffc   \n",
       "172712  0.830           -1            1  False  5daa3d1726488800157a6ffc   \n",
       "\n",
       "        response  catCong  subject  rewpunLevel  \n",
       "0              1       -1        0            1  \n",
       "1              1        1        0            1  \n",
       "2              1       -1        0            1  \n",
       "3              1        1        0            1  \n",
       "4              1        1        0            1  \n",
       "...          ...      ...      ...          ...  \n",
       "172708         1        1      315           -1  \n",
       "172709         1       -1      315           -1  \n",
       "172710         1       -1      315           -1  \n",
       "172711         1        1      315           -1  \n",
       "172712         1        1      315           -1  \n",
       "\n",
       "[165348 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_commission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20f08e-20f8-49a7-8ad6-13ae1e3e3bf5",
   "metadata": {},
   "source": [
    "# Create the pytensor OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3044adc-cca4-42b3-a7b0-4faffb2c5e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate LAN logp functions\n",
    "lan_logp_jitted, lan_logp_vjp_jitted, lan_logp = NetworkLike.make_logp_jax_funcs(model = forward_pass_lan,\n",
    "                                                                                  n_params = 6,\n",
    "                                                                                  kind = \"lan\",\n",
    "                                                                                  list_params = ['v','a','z','t','theta','p_outlier'],\n",
    "                                                                                  bounds = {'v':(-3,3),\n",
    "                                                                                            'a':(0.2,2.5),\n",
    "                                                                                            'z':(0.1,0.9),\n",
    "                                                                                            't':(0.01,0.5),\n",
    "                                                                                            'theta':(0,1.2),\n",
    "                                                                                            'p_outlier':(0,0.05)},\n",
    "                                                                                  params_is_reg=[True,True,True,True,True,False])\n",
    "\n",
    "# Turn into logp op\n",
    "lan_logp_op = NetworkLike.make_jax_logp_ops(\n",
    "                                logp = lan_logp_jitted,\n",
    "                                logp_vjp = lan_logp_vjp_jitted,\n",
    "                                logp_nojit = lan_logp)\n",
    "\n",
    "# Instantiate CPN logp functions\n",
    "cpn_logp_jitted, cpn_logp_vjp_jitted, cpn_logp = NetworkLike.make_logp_jax_funcs(model = forward_pass_cpn,\n",
    "                                                                                 n_params = 6,\n",
    "                                                                                 list_params = ['v','a','z','t','theta','deadline'],\n",
    "                                                                                 bounds = {'v':(-3,3),\n",
    "                                                                                           'a':(0.2,2.5),\n",
    "                                                                                           'z':(0.1,0.9),\n",
    "                                                                                           't':(0.01,0.5),\n",
    "                                                                                           'theta':(0,1.2)},\n",
    "                                                                                 kind = \"cpn\",\n",
    "                                                                                 params_is_reg=[True,True,True,True,True,False])\n",
    "\n",
    "# Turn into logp op\n",
    "cpn_logp_op = NetworkLike.make_jax_logp_ops(\n",
    "                                logp = cpn_logp_jitted,\n",
    "                                logp_vjp = cpn_logp_vjp_jitted,\n",
    "                                logp_nojit = cpn_logp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d6de6-e292-4e74-8395-d1bf51e6883b",
   "metadata": {},
   "source": [
    "# Run the fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7770b-de9a-4240-a083-e31e7d1fc4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing through identity\n",
      "passing through transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compilation time = 0:00:08.532185\n",
      "Sampling...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing through transform\n",
      "passing through identity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b9821e79b647caaf25a2800e56e6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a1f925d9424a55b08ee629c0a4c4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing through transform\n",
      "passing through identity\n"
     ]
    }
   ],
   "source": [
    "coords = {\n",
    "    \"id\": df.subject.unique(),  # actual group names\n",
    "    \"observation1\": np.arange(df_commission.shape[0]),  # or use this, `data.index.values\n",
    "    \"observation2\": np.arange(df.shape[0])\n",
    "}\n",
    "\n",
    "with pm.Model(coords=coords) as hierarchical:\n",
    "    # Hyperpriors\n",
    "    mu_v = pm.Normal('mu_v',mu=0,sigma=1)\n",
    "    sigma_v = pm.HalfCauchy('sigma_v',beta=0.2)\n",
    "    v_subj = pm.Normal('v_subj',mu=0,sigma=1,dims='id')\n",
    "\n",
    "    mu_v_catRewLevel = pm.Normal('v_catRewLevel',mu=0,sigma=1)\n",
    "    sigma_v_catRewLevel = pm.HalfCauchy('sigma_v_catRewLevel',beta=0.2)\n",
    "    v_catRewLevel_subj = pm.Normal('v_catRewLevel_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_a_catRewLevel = pm.Normal('a_catRewLevel',mu=0,sigma=1)\n",
    "    sigma_a_catRewLevel = pm.HalfCauchy('sigma_a_catRewLevel',beta=0.2)\n",
    "    a_catRewLevel_subj = pm.Normal('a_catRewLevel_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_theta_catRewLevel = pm.Normal('theta_catRewLevel',mu=0,sigma=1)\n",
    "    sigma_theta_catRewLevel = pm.HalfCauchy('sigma_theta_catRewLevel',beta=0.2)\n",
    "    theta_catRewLevel_subj = pm.Normal('theta_catRewLevel_subj',mu=0,sigma=1,dims='id')    \n",
    "\n",
    "    mu_v_catRewLevelcatPunLevel = pm.Normal('v_catRewLevelcatPunLevel',mu=0,sigma=0.5)\n",
    "    sigma_v_catRewLevelcatPunLevel = pm.HalfCauchy('sigma_v_catRewLevelPunLevel',beta=0.2)\n",
    "    v_catRewLevelcatPunLevel_subj = pm.Normal('v_catRewLevelcatPunLevel_subj',mu=0,\n",
    "                                              sigma=1,dims='id')\n",
    "    mu_a_catRewLevelcatPunLevel = pm.Normal('a_catRewLevelcatPunLevel',mu=0,sigma=0.5)\n",
    "    sigma_a_catRewLevelcatPunLevel = pm.HalfCauchy('sigma_a_catRewLevelcatPunLevel',beta=0.2)\n",
    "    a_catRewLevelcatPunLevel_subj = pm.Normal('a_catRewLevelcatPunLevel_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_theta_catRewLevelcatPunLevel = pm.Normal('theta_catRewLevelcatPunLevel',mu=0,sigma=0.5)\n",
    "    sigma_theta_catRewLevelcatPunLevel = pm.HalfCauchy('sigma_theta_catRewLevelcatPunLevel',beta=0.2)\n",
    "    theta_catRewLevelcatPunLevel_subj = pm.Normal('theta_catRewLevelcatPunLevel_subj',mu=0,sigma=1,dims='id')    \n",
    "\n",
    "    mu_v_cong = pm.Normal('v_cong',mu=0,sigma=1)\n",
    "    sigma_v_cong = pm.HalfCauchy('sigma_v_cong',beta=0.2)\n",
    "    v_cong_subj = pm.Normal('v_cong_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_a_cong = pm.Normal('a_cong',mu=0,sigma=1)\n",
    "    sigma_a_cong = pm.HalfCauchy('sigma_a_cong',beta=0.2)\n",
    "    a_cong_subj = pm.Normal('a_cong_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_theta_cong = pm.Normal('theta_cong',mu=0,sigma=1)\n",
    "    sigma_theta_cong = pm.HalfCauchy('sigma_theta_cong',beta=0.2)\n",
    "    theta_cong_subj = pm.Normal('theta_cong_subj',mu=0,sigma=1,dims='id')   \n",
    "    \n",
    "    mu_z_cong = pm.Normal('z_cong',mu=0,sigma=1)\n",
    "    sigma_z_cong = pm.HalfCauchy('sigma_z_cong',beta=0.2)\n",
    "    z_cong_subj = pm.Normal('z_cong_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_v_catPunLevel = pm.Normal('v_catPunLevel',mu=0,sigma=1)\n",
    "    sigma_v_catPunLevel = pm.HalfCauchy('sigma_v_catPunLevel',beta=0.2)\n",
    "    v_catPunLevel_subj = pm.Normal('v_catPunLevel_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_a_catPunLevel = pm.Normal('a_catPunLevel',mu=0,sigma=1)\n",
    "    sigma_a_catPunLevel = pm.HalfCauchy('sigma_a_catPunLevel',beta=0.2)\n",
    "    a_catPunLevel_subj = pm.Normal('a_catPunLevel_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_theta_catPunLevel = pm.Normal('theta_catPunLevel',mu=0,sigma=1)\n",
    "    sigma_theta_catPunLevel = pm.HalfCauchy('sigma_theta_catPunLevel',beta=0.2)\n",
    "    theta_catPunLevel_subj = pm.Normal('theta_catPunLevel_subj',mu=0,sigma=1,dims='id')    \n",
    " \n",
    "    mu_theta = pm.Normal('mu_theta',mu=0,sigma=1)\n",
    "    sigma_theta = pm.HalfCauchy('sigma_theta',beta=0.2)\n",
    "    theta_subj = pm.Normal('theta_subj',mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_a = pm.Normal('mu_a',mu=0,sigma=1)\n",
    "    sigma_a = pm.HalfCauchy('sigma_a',beta=0.2)\n",
    "    a_subj = pm.Normal('a_subj',mu=0,sigma=1,dims='id')\n",
    "        \n",
    "    mu_z = pm.Normal(\"mu_z\", mu=0,sigma=1)\n",
    "    sigma_z = pm.HalfCauchy(\"sigma_z\",beta=0.2)\n",
    "    z_subj = pm.Normal(\"z_subj\", mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_t = pm.Normal(\"mu_t\", mu=0,sigma=1)\n",
    "    sigma_t = pm.HalfCauchy(\"sigma_t\",beta=0.2)\n",
    "    t_subj = pm.Normal(\"t_subj\", mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    mu_p = pm.Normal(\"mu_p\", mu=0,sigma=1)\n",
    "    sigma_p = pm.HalfCauchy(\"sigma_p\",beta=0.2)\n",
    "    p_subj = pm.Normal(\"p_subj\", mu=0,sigma=1,dims='id')\n",
    "    \n",
    "    # p_outlier = pm.Normal(\"p_outlier\", mu=0,sigma=1)\n",
    "    # deadline = pm.ConstantData('deadline',1.25)\n",
    "\n",
    "    idx1 = pm.ConstantData('idx1',df_commission.subject,dims='observation1')\n",
    "    idx2 = pm.ConstantData('idx2',df.subject,dims='observation2')\n",
    "    \n",
    "    rewardLevel1 = pm.ConstantData('rewardLevel1',df_commission.catRewLevel,dims='observation1')\n",
    "    rewardLevel2 = pm.ConstantData('rewardLevel2',df.catRewLevel,dims='observation2')\n",
    "    punishLevel1 = pm.ConstantData('punishLevel1',df_commission.catPunLevel,dims='observation1')\n",
    "    punishLevel2 = pm.ConstantData('punishLevel2',df.catPunLevel,dims='observation2')\n",
    "    rewpun1 = pm.ConstantData('rewpun1',df_commission.rewpunLevel,dims='observation1')\n",
    "    rewpun2 = pm.ConstantData('rewpun2',df.rewpunLevel,dims='observation2')\n",
    "    cong1 = pm.ConstantData('cong1',df_commission.catCong,dims='observation1')\n",
    "    cong2 = pm.ConstantData('cong2',df.catCong,dims='observation2')\n",
    "    \n",
    "    v_trial1 = pm.Deterministic('v_trial1',v_subj[idx1] * sigma_v + mu_v + \n",
    "                                rewardLevel1 * (v_catRewLevel_subj[idx1] * sigma_v_catRewLevel + mu_v_catRewLevel) + \n",
    "                                punishLevel1 * (v_catPunLevel_subj[idx1] * sigma_v_catPunLevel + mu_v_catPunLevel) +\n",
    "                                cong1 * (v_cong_subj[idx1] * sigma_v_cong + mu_v_cong) + \n",
    "                                rewpun1 * (v_catRewLevelcatPunLevel_subj[idx1] * sigma_v_catRewLevelcatPunLevel + mu_v_catRewLevelcatPunLevel))\n",
    "    v_trial2 = pm.Deterministic('v_trial2',v_subj[idx2] * sigma_v + mu_v + \n",
    "                                rewardLevel2 * (v_catRewLevel_subj[idx2] * sigma_v_catRewLevel + mu_v_catRewLevel) + \n",
    "                                punishLevel2 * (v_catPunLevel_subj[idx2] * sigma_v_catPunLevel + mu_v_catPunLevel) +\n",
    "                                cong2 * (v_cong_subj[idx2] * sigma_v_cong + mu_v_cong) + \n",
    "                                rewpun2 * (v_catRewLevelcatPunLevel_subj[idx2] * sigma_v_catRewLevelcatPunLevel + mu_v_catRewLevelcatPunLevel))\n",
    "    a_trial1 = pm.Deterministic('a_trial1',a_subj[idx1] * sigma_a + mu_a + \n",
    "                                rewardLevel1 * (a_catRewLevel_subj[idx1] * sigma_a_catRewLevel + mu_a_catRewLevel) + \n",
    "                                punishLevel1 * (a_catPunLevel_subj[idx1] * sigma_a_catPunLevel + mu_a_catPunLevel) +\n",
    "                                cong1 * (a_cong_subj[idx1] * sigma_a_cong + mu_a_cong) + \n",
    "                                rewpun1 * (a_catRewLevelcatPunLevel_subj[idx1] * sigma_a_catRewLevelcatPunLevel + mu_a_catRewLevelcatPunLevel))\n",
    "    a_trial2 = pm.Deterministic('a_trial2',a_subj[idx2] * sigma_a + mu_a + \n",
    "                                rewardLevel2 * (a_catRewLevel_subj[idx2] * sigma_a_catRewLevel + mu_a_catRewLevel) + \n",
    "                                punishLevel2 * (a_catPunLevel_subj[idx2] * sigma_a_catPunLevel + mu_a_catPunLevel) +\n",
    "                                cong2 * (a_cong_subj[idx2] * sigma_a_cong + mu_a_cong) + \n",
    "                                rewpun2 * (a_catRewLevelcatPunLevel_subj[idx2] * sigma_a_catRewLevelcatPunLevel + mu_a_catRewLevelcatPunLevel))\n",
    "    theta_trial1 = pm.Deterministic('theta_trial1',theta_subj[idx1] * sigma_theta + mu_theta + \n",
    "                                rewardLevel1 * (theta_catRewLevel_subj[idx1] * sigma_theta_catRewLevel + mu_theta_catRewLevel) + \n",
    "                                punishLevel1 * (theta_catPunLevel_subj[idx1] * sigma_theta_catPunLevel + mu_theta_catPunLevel) +\n",
    "                                cong1 * (theta_cong_subj[idx1] * sigma_theta_cong + mu_theta_cong) + \n",
    "                                rewpun1 * (theta_catRewLevelcatPunLevel_subj[idx1] * sigma_theta_catRewLevelcatPunLevel + mu_theta_catRewLevelcatPunLevel))\n",
    "    theta_trial2 = pm.Deterministic('theta_trial2',theta_subj[idx2] * sigma_theta + mu_theta + \n",
    "                                rewardLevel2 * (theta_catRewLevel_subj[idx2] * sigma_theta_catRewLevel + mu_theta_catRewLevel) + \n",
    "                                punishLevel2 * (theta_catPunLevel_subj[idx2] * sigma_theta_catPunLevel + mu_theta_catPunLevel) +\n",
    "                                cong2 * (theta_cong_subj[idx2] * sigma_theta_cong + mu_theta_cong) + \n",
    "                                rewpun2 * (theta_catRewLevelcatPunLevel_subj[idx2] * sigma_theta_catRewLevelcatPunLevel + mu_theta_catRewLevelcatPunLevel))\n",
    "    z_trial1 = pm.Deterministic('z_trial1',z_subj[idx1] * sigma_z + mu_z + cong1 * (z_cong_subj[idx1] * sigma_z_cong + mu_z_cong))  \n",
    "    z_trial2 = pm.Deterministic('z_trial2',z_subj[idx2] * sigma_z + mu_z + cong2 * (z_cong_subj[idx2] * sigma_z_cong + mu_z_cong))\n",
    "    \n",
    "    t_trial1 = pm.Deterministic('t_trial1',t_subj[idx1] * sigma_t + mu_t)  \n",
    "    t_trial2 = pm.Deterministic('t_trial2',t_subj[idx2] * sigma_t + mu_t)  \n",
    "\n",
    "        t_trial1 = pm.Deterministic('t_trial1',t_subj[idx1] * sigma_t + mu_t)  \n",
    "    t_trial2 = pm.Deterministic('t_trial2',t_subj[idx2] * sigma_t + mu_t)  \n",
    "\n",
    "    pm.CustomDist(\"choice_rt\", v_trial1,\n",
    "                                          a_trial1,\n",
    "                                          z_trial1, \n",
    "                                          t_trial1, \n",
    "                                          theta_trial1,\n",
    "                                          p_outlier,\n",
    "                 logp=lan_logp_op,observed=df_commission[['rt','response']])\n",
    "    pm.CustomDist(\"omission\", v_trial2,\n",
    "                                         a_trial2, \n",
    "                                         z_trial2, \n",
    "                                         t_trial2, \n",
    "                                         theta_trial2,\n",
    "                                         deadline,\n",
    "                 logp=cpn_logp_op,observed=df['oe'])   \n",
    "    ddm_blog_traces_numpyro_d = pmj.sample_numpyro_nuts(\n",
    "            chains=2, draws=1000, tune=500,initvals={'mu_v':0,'mu_a':0,'mu_theta':0,\"mu_z\":0,\"mu_t\":0,\"v_catRewLevel\":0,\"a_catRewLevel\":0,\n",
    "                                                    'theta_catRewLevel':0,\"v_catPunLevel\":0,\"a_catPunLevel\":0,\n",
    "                                                    'theta_catPunLevel':0,\"v_cong\":0,\"a_cong\":0,\n",
    "                                                    'theta_cong':0,'z_cong':0,'v_catRewLevelcatPunLevel':0,\n",
    "                                                    'a_catRewLevelcatPunLevel':0,'theta_catRewLevelcatPunLevel':0}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a45133-5bd9-4b4f-bc41-c5ad24349739",
   "metadata": {},
   "source": [
    "# Function to extract and plot traces that I'm interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa430e0a-c9cf-4eb0-a16a-80da21dd262a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mytraceplot(trace):\n",
    "    keep = [x for x in trace.posterior.data_vars.keys() if x[-6:-1] != 'trial']\n",
    "    pm.plot_trace(trace, keep)\n",
    "\n",
    "    \n",
    "def mysummary(trace):\n",
    "    keep = [x for x in trace.posterior.data_vars.keys() if x[-6:-1] != 'trial']\n",
    "    return pm.summary(trace, keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01218148-69ce-4f90-b74c-1e1ceeddad84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "\n",
    "a = mysummary(idata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27bc49-2566-4eb7-a541-e8eb88ac2848",
   "metadata": {},
   "source": [
    "# Tried to estimate LL from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de9733b7-42d0-4c6a-bb13-e2f31613deaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='400' class='' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [400/400 00:54&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with hierarchical:\n",
    "    a = pm.compute_log_likelihood(ddm_blog_traces_numpyro_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "922912e9-9a9b-4e64-943e-13491fbe4f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computed from 400 posterior samples and 164376 observations log-likelihood matrix.\n",
       "\n",
       "          Estimate       SE\n",
       "elpd_waic -17555.59   256.33\n",
       "p_waic      715.00        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.waic(a,var_name='omission')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lan_pipe2",
   "language": "python",
   "name": "lan_pipe2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
